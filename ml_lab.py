# -*- coding: utf-8 -*-
"""ML_Lab.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1jeAIg8ukMpLlrpPKjPGENBJkvgYIVidM
"""

import pandas as pd

df = pd.read_csv("/content/dataset_1 (1).data")

print(df.head())

df.shape

df.describe()

df.isnull()

Headers = ["symboling","normalized-losses","make","fuel-type","aspiration", "num-of-doors","body-style",
         "drive-wheels","engine-location","wheel-base", "length","width","height","curb-weight","engine-type",
         "num-of-cylinders", "engine-size","fuel-system","bore","stroke","compression-ratio","horsepower",
         "peak-rpm","city-mpg","highway-mpg","price"]

from os import name
df = pd.read_csv("/content/dataset_1 (1).data" , names = Headers)
print(df.head(10))

df.isnull()

df.replace("?" , np.nan ,inplace = True)
df.head(10)

missing_data = df.isnull()
missing_data.head(10)

for column in missing_data.columns.values.tolist():
  print(column)
  print(missing_data[column].value_counts())
  print("")

from sklearn.impute import SimpleImputer
imputer = SimpleImputer(missing_values=np.nan , strategy = 'mean')
imputer.fit(df[['normalized-losses','stroke','bore','horsepower','peak-rpm']])
df[['normalized-losses','stroke','bore','horsepower','peak-rpm']] = imputer.transform(df[['normalized-losses','stroke','bore','horsepower','peak-rpm']])

from sklearn.impute import SimpleImputer
imputer = SimpleImputer(missing_values=np.nan , strategy = 'most_frequent')
imputer.fit(df[['num-of-doors']])
df[['num-of-doors']] = imputer.transform(df[['num-of-doors']])

df.head(10)

import numpy as np

from sklearn.linear_model import LinearRegression
weight = np.array([50,60,70,80,90,100]).reshape(-1,1)
height = np.array([150,155,160,165,170,175])
model = LinearRegression()

model.fit(weight,height)

user_weight = float(input("Enter weight in kg:"))

predicted_height = model.predict([[user_weight]])
print(f"Predicted Height for {user_weight} kg: {predicted_height[0]: 2f} cm")

from sklearn.linear_model import LinearRegression
study_hours = np.array([4,5,6,7,8,9]).reshape(-1,1)
marks = np.array([30,40,50,60,70,80])
model = LinearRegression()

model.fit(study_hours,marks)

user_hours = float(input("Enter study hours:"))

predicted_marks = model.predict([[user_hours]])
print(f"Predicted marks for {user_hours} Hours/day : {predicted_marks[0]: 2f}")

from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
import pandas as pd
import seaborn as sns
from sklearn.datasets import load_iris

X=load_iris().data
Y=load_iris().target

X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=42)

model = LogisticRegression(max_iter=200)
model.fit(X_train, Y_train)
predictions = model.predict(X_test)

print("Accuracy:", accuracy_score(Y_test, predictions))
print("Classification Report:\n", classification_report(Y_test, predictions))
print("Confusion Matrix:\n", confusion_matrix(Y_test, predictions))

import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import r2_score, mean_squared_error
data = {
    "Height": [172,162,187,134,166,178],
    "weight": [200,74,56,67,86,56],
    "BMI":[18,19,25,20,23,34]
}
df = pd.DataFrame(data)
X = df[["Height", "weight"]]
y = df["BMI"]
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
model = LinearRegression()
model.fit(X_train, y_train)
print("Intercept (b0):", model.intercept_)
print("Coefficients (b1, b2):", model.coef_)
y_pred = model.predict(X_test)
print("R2 Score:", r2_score(y_test, y_pred))
print("Mean Squared Error:", mean_squared_error(y_test, y_pred))
results = pd.DataFrame({"Actual": y_test, "Predicted": y_pred})
print(results)

import pandas as pd

df = pd.read_csv("/content/Coffee_Chain_Sales .csv")

from sklearn import datasets
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score , confusion_matrix, classification_report
import numpy as np

digits = datasets.load_digits()
X = digits.data
y = digits.target

print("Dataset Shape:" , X.shape)
print("Target Shape:" , y.shape)

plt.gray()
plt.matshow(digits.images[0])
plt.title(f"Sample Digit: {digits.target[0]}")
plt.show()
X_train , X_test , y_train , y_test = train_test_split(
    X,y,test_size = 0.3 , random_state=42
)

scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

k = 5
knn = KNeighborsClassifier(n_neighbors=k)
knn.fit(X_train , y_train)

y_pred = knn.predict(X_test)

print("\nModel Accuracy:", accuracy_score(y_test , y_pred))
print("\nConfusion Matrix:\n", confusion_matrix(y_test , y_pred))
print("\nClassification Report:\n", classification_report(y_test , y_pred))

sample_index = 10
sample_image = X_test[sample_index].reshape(1,-1)
predicted_label = knn.predict(sample_image)

print(f"\nPrediction for test image[{sample_index}] {predicted_label[0]}")
print(f"Actual Label {y_test[sample_index]}")

plt.gray()
plt.matshow(digits.images[y_test[sample_index]])
plt.title(f"predicted: {predicted_label[0]} | Actual: {y_test[sample_index]}")
plt.show()

import kagglehub

# Download latest version
path = kagglehub.dataset_download("aksha05/flower-image-dataset")

print("Path to dataset files:", path)

import pandas as pd

df = pd.read_csv("/content/bmw.csv")

df.head()

df.info()

df.describe()

df.isnull().sum()

from sklearn.preprocessing import LabelEncoder
le = LabelEncoder()
for col in df.select_dtypes(include=['object']).columns:
    df[col] = le.fit_transform(df[col])
print(df.head())

